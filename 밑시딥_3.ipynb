{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49087dc9",
   "metadata": {},
   "source": [
    "## 3. 신경망\n",
    "---  \n",
    "- 퍼셉트론은 가중치를 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851a588c",
   "metadata": {},
   "source": [
    "### 3.1 퍼셉트론에서 신경망으로\n",
    "---\n",
    " - 신경망과 퍼셉트론의 차이를 구조적으로 표현!\n",
    " - 퍼셉트론과 신경망의 큰 차이? \n",
    "\n",
    "#### 3.1.1 신경망의 예\n",
    "- 신경망 : 퍼셉트론\n",
    "\n",
    "- 뉴런은 생물학적 관점으로 바라본 것, 노드는 프로그래밍 관점에서 바라 본 것.\n",
    "\n",
    "참고 읽을 거리)\n",
    "1. 신경망의 개녕 https://www.youtube.com/watch?v=bxe2T-V8XRs&feature=youtu.be\n",
    "2. 신경망과 딥러닝의 역사 https://www.skynettoday.com/overviews/neural-net-history\n",
    "3. 신경망과 딥러닝 E-book http://neuralnetworksanddeeplearning.com/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273686c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23, 53, 83])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[1,2],[3,4],[5,6]])\n",
    "A.shape # (3,2)\n",
    "\n",
    "B = np.array([7,8])\n",
    "B.shape # (2,)\n",
    "\n",
    "np.dot(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f0302",
   "metadata": {},
   "source": [
    "### 생각해보기 (토론주제)\n",
    "---\n",
    "**1. 퍼셉트론과 신경망의 차이는 무엇일까요?**  \n",
    "- 둘다 앞서 매개변수에 가중치를 곱하고 편향값을 더한 식을 활성화함수로 사용함. \n",
    "- 퍼셉트론은 활성화 함수로 계단함수를 사용함. -> 0 또는 1만 출력\n",
    "- 퍼셉트론은 선형함수...?\n",
    "- 신경망은 signmoid, ReLU 같이 연속적인 값(부드러운 모양)의 그래프를 사용함 => 비선형 형태의 그래프 사용\n",
    "\n",
    "\n",
    "**2. 은닉층의 값을 볼 수 있는 방법은 없을까요?**  \n",
    "- 출력층까지의 조건을 계속 부여해줘서 끊어서 프린트하면 볼 수 있지 않을까요?? (수치화 데이터만 가능)\n",
    "- 입력층, 출력층은 우리가 볼 수 있음. 중간과정은 \n",
    "- \n",
    "\n",
    "\n",
    "**3. 신경망에 활성화 함수 유무에 따라 어떤 차이가 발생할까요?**  \n",
    "- 그냥 이분법적인 0,1을 출력하는 것이 아니기 때문에.....\n",
    "- 어떤 값을 넘길지 결정... -> 있고 없고에 따라 활성화 값을 나눌 수 있음. 게이트... 활성화 함수에 따라서 어떤 뉴련을 활성화할지 결정하는 것. \n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99df09f",
   "metadata": {},
   "source": [
    "### 3.2 활성화 함수\n",
    "---\n",
    " - 활성화 함수 : 어떤 노드를 활성/비활성 결정하기 위함 \n",
    " - 활성화 함수는 여러 후보 중 퍼셉트론은 계단함수를 사용함. \n",
    " 3.2.1시그모이드 함수\n",
    " - 시그모이드 x값에 우리 앞에서 적었던 wx + b의 형식이 들어감. \n",
    " - 시그모이드는 0 ~ 1의 값을 다타내는 S자 그래프를 가짐 \n",
    " - 시그모이드를 한번 말고 여러번 쓰면? 0.5 이하라면 0에 수렴할 것. 가중치 값이 작아져서 소실됨. -> 이를 보완하기 위한 것이 ReLU.\n",
    " - 가중치의 표현범위가 0 ~ 1로 범위를 정규화 하기 위해 사용함. (중첩해서 쓴다면 1번째 그래프 값에서 계속 됨. 0~10 에서 3은 0.3 -> 한번더 하면 0.03 -> 0.003 같은 형식으로)\n",
    " \n",
    " 렐루\n",
    " - 0이하면 0, 그 이상은 그 값을 출력함. \n",
    " - 0.3이면 0.3그대로 출력. -0.3이면 0 출력 -> 가중치가 0에 가까울수록 중요도가 떨어지는 것 -> 0 이하는 0으로 치는 것. 어떤 가중치를 갖는다면 그 중요도를 그대로 하는 것. 중요도가 클수록 큰 값을 나타냄. \n",
    " - 장점 : 기울기가 소실되지 않음. \n",
    " - \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "참고 읽을 거리)\n",
    "- 활성화 함수 종류 및 특징 간단하게 살펴보기 : https://muzukphysics.tistory.com/165?category=1111219  \n",
    "- 활성화 함수 상세 설명 : https://reniew.github.io/12/\n",
    "- 활성화 함수를 알아야 하는 이유 : https://velog.io/@hyunsuki/Activation-Function%ED%99%9C%EC%84%B1%ED%99%94-%ED%95%A8%EC%88%98"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784803b5",
   "metadata": {},
   "source": [
    "### 생각해보기 (토론주제)  \n",
    "1. 활성화 되지 않은 노드는 어떻게 될까요?  \n",
    "- 활성화 함수는 0이라도 출력을 하지만, 활성화가 되지 않는다면 아예 출력이 없음. -> 그림에서 선을 지움 (동동 떠다님 -> 사라짐 dropout). 0이면 선은 있음. \n",
    "\n",
    "\n",
    "2. 계단 함수는 어떤 용도로 사용되는 함수일까요?  \n",
    "- 단순 스위치 같은 용도\n",
    "\n",
    "\n",
    "3. 시그모이드 함수는 어떤용도로 사용되는 함수일까요?  \n",
    "- 확률을 출력으로 예측해야 하는 모델에 일반적으로 사용된다. 확률은 0과 1 사이에만 존재하므로 범위이기 때문  -> 정규화\n",
    "- 하지만 딥러닝 모델이 깊으면 깊을수록 기울기가 사라지는 Gradient Vanishing 현상이 발생함 -> 딥러닝 모델에서 추천하지 않음 \n",
    "\n",
    "\n",
    "4. 시그모이드 함수와 비슷한 기법은 어떤것이 있을까요?  \n",
    "- 로지스틱(Logistic)함수 : 값이 -무한대 ~ +무한대로 됨\n",
    "- 하이퍼볼릭 탄젠트(Hyperbolic Tangent) : 함수의 결과를 -1 ~ 1 사이의 비선형 형태로 변경함.  \n",
    "\n",
    "\n",
    "5. 시그모이드 함수와 ReLU함수는 어떤점이 다를까요?  \n",
    "- 음력이 양수일때는 x, 음수일때는 0을 출력함. \n",
    "- 경사하강에 영향을 주지 않아 다른 활성화 함수에 비해 학습이 빠른 장점  \n",
    "- **Gradient Vanishing 문제가 발생하지 않음**\n",
    "- 보통 Hidden Layer에 사용됨.  \n",
    "- 문제점은 음수 값을 입력받으면 항상 0이기 때문에 \n",
    "\n",
    "\n",
    "6. 활성화 함수로 선형 함수를 사용하면 어떤 문제점이 있을까요?  \n",
    "- 기울기가 일정하기때문에 역전파...?\n",
    "- 비선형이면 선을 지나는 지점에 따라 기울기를 바꿀 수 있음. \n",
    "\n",
    "\n",
    "추가Q. 층을 쌓는 이유?  \n",
    "- 1) 특징을 많이 찾아낼 수 있음. \n",
    "2) 해상도를 줄임으로 학습이 잘 되었을 때 연산을 적게할 수 잇음 (모듈의 처리속도가 빠름)\n",
    "3) 케이스가 많으니 오차율을 줄일 수 있음.\n",
    "하지만 깊게 쌓을수록 오류날 확률 많음. \n",
    "은닉층의 깊이는 모델의 경험 -> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77591ab8",
   "metadata": {},
   "source": [
    "### 다차원 배열의 계산\n",
    "---\n",
    "\n",
    "- 행렬과 행렬의 곱을 어떻게 할 것인가. \n",
    "- NumPy에서 어껗게 구현하느냐. \n",
    "- 행렬과 곱할때 앞행렬의 뒷차원과 뒷행렬의 앞차원이 동일해야함. \n",
    "- 넘파이로 구현시 array, np.dot을 기억하면 파이선에서 행렬연산을 쉽게 할 수 있음. 필요한 이유는 히든레이어를 개설할 때 행렬의 곱을 계속해서 해야하기 때문에 쉽게 계산하기 편하게 하기 위해서. \n",
    "\n",
    "\n",
    "\n",
    "참고 읽을 거리)\n",
    "- Numpy 다차원 배열 : https://datascienceschool.net/01%20python/03.01%20%EB%84%98%ED%8C%8C%EC%9D%B4%20%EB%B0%B0%EC%97%B4.html\n",
    "- Numpy 배열에 유용한 메소드 : https://bskyvision.com/748\n",
    "- Numpy 배열 상세 설명 : https://compmath.korea.ac.kr/appmath/NumpyBasics.html\n",
    "- 행렬 곱 연산 매커니즘 : https://velog.io/@joo4438/%EB%8B%A4%EC%B0%A8%EC%9B%90-%EB%B0%B0%EC%97%B4%EC%9D%98-%EA%B3%84%EC%82%B0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5590229",
   "metadata": {},
   "source": [
    "### 생각해보기 (토론주제)  \n",
    "---\n",
    "1. numpy로 3차원 이상의 N차원 배열을 구성했을 때 어떤 모습일까요?  \n",
    "- 알수없다!!!!!!\n",
    "- 고유벡터의 갯수가 곧 차원 수 \n",
    "\n",
    "\n",
    "2. 행렬 곱에서 대응하는 차원의 원소 수를 일치하는 이유는 무엇일까요?\n",
    "- 행렬을 통해서 입력 데이터와 가중치의 값? 특성을 곱해서 출력을 하기때문에, 차원의 원소수를 맞춰주지않으면 오류가 남\n",
    "- 연산이 되어야하니까! \n",
    "- (m x k) x (k x n) = (m x n)에서 k는 곱해지면서 특성이 n에 반영이 됨\n",
    "\n",
    "3. 신경망에서 행렬 곱을 하는 이유가 무엇일까요?\n",
    "- 이를 통해 for문을 이용해 곱을 해줘야 하는데, 이를 행렬로 바꿈으로써 한번의 연산으로 쉽게 구할 수 있기 때문\n",
    "- 정보의 합성을 위해서!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
